DEEP-MUSIC GENERATOR is an innovative application that utilizes deep learning models to generate music. The app integrates various models, including CNN, LSTM, and RNN, to create a hybrid and stacked deep learning model. The stacked model is formed by stacking three existing models, while the hybrid model incorporates different CNN, LSTM, and RNN layers to each input phase, and reshapes the input and output using reshape layers.
To compile the model, the categorical_crossentropy and "Adam" Optimizer are utilized. The hybrid model has achieved the highest accuracy among the models. Fortunately, users can access these powerful models through the app's web interface. By simply uploading the music and selecting the desired prediction portion, users can generate newly created music.
It is worth noting that this project is protected by copyright and has been a successful undertaking.
Certification image:- 
![Deep Music Genaretor_page-0001(1)](https://github.com/Hrithik0the0research/Music-generate/assets/121748257/f8b04765-7c15-4910-a5d8-e9bfd470c533)


Link for web-app: https://hrithik0the0research-music-generate-web-interface-gpv6un.streamlit.app/
(Note: It can be seen that the web app is in sleep mode, as it automatically detects not traffic, click "Yes, get this app back up!" and wait some moments it will be opened automatically)
The web-app only takes mid file right now as mid file is good for taking the notes from it but for future upgrade we are going to add features for .mp3 and other extension audio files.

Video link: 



https://github.com/Hrithik0the0research/Music-generate/assets/121748257/9ee3779f-f589-4774-b476-fef63da133f9

