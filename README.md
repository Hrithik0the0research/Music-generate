Music-Genapp is an innovative application that utilizes deep learning models to generate music. The app integrates various models, including CNN, LSTM, and RNN, to create a hybrid and stacked deep learning model. The stacked model is formed by stacking three existing models, while the hybrid model incorporates different CNN, LSTM, and RNN layers to each input phase, and reshapes the input and output using reshape layers.
To compile the model, the categorical_crossentropy and "Adam" Optimizer are utilized. The hybrid model has achieved the highest accuracy among the models. Fortunately, users can access these powerful models through the app's web interface. By simply uploading the music and selecting the desired prediction portion, users can generate newly created music.
It is worth noting that this project is protected by copyright and has been a successful undertaking.
Link for web-app: https://hrithik0the0research-music-generate-web-interface-gpv6un.streamlit.app/
(Note: It can be seen that the web app is in sleep mode, as it automatically detects not traffic)
